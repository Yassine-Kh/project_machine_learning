{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from sklearn.metrics import plot_roc_curve\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe looks like this: \n",
      "\n",
      "    3.6216  8.6661  -2.8073  -0.44699  0\n",
      "0  4.54590  8.1674  -2.4586  -1.46210  0\n",
      "1  3.86600 -2.6383   1.9242   0.10645  0\n",
      "2  3.45660  9.5228  -4.0112  -3.59440  0\n",
      "3  0.32924 -4.4552   4.5718  -0.98880  0\n",
      "4  4.36840  9.6718  -3.9606  -3.16250  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.755273</td>\n",
       "      <td>0.749748</td>\n",
       "      <td>0.143658</td>\n",
       "      <td>0.744387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.762088</td>\n",
       "      <td>0.563374</td>\n",
       "      <td>0.310755</td>\n",
       "      <td>0.940860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0.377698</td>\n",
       "      <td>0.260396</td>\n",
       "      <td>0.516424</td>\n",
       "      <td>0.883485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.647809</td>\n",
       "      <td>0.532714</td>\n",
       "      <td>0.427910</td>\n",
       "      <td>0.876192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.496219</td>\n",
       "      <td>0.273556</td>\n",
       "      <td>0.587736</td>\n",
       "      <td>0.638915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.192934</td>\n",
       "      <td>0.742470</td>\n",
       "      <td>0.252361</td>\n",
       "      <td>0.280186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.217835</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.900597</td>\n",
       "      <td>0.690302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.151252</td>\n",
       "      <td>0.638870</td>\n",
       "      <td>0.273509</td>\n",
       "      <td>0.645971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.336225</td>\n",
       "      <td>0.461479</td>\n",
       "      <td>0.276279</td>\n",
       "      <td>0.791889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.337437</td>\n",
       "      <td>0.511421</td>\n",
       "      <td>0.311013</td>\n",
       "      <td>0.880548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis   entropy\n",
       "274   0.755273  0.749748  0.143658  0.744387\n",
       "323   0.762088  0.563374  0.310755  0.940860\n",
       "1097  0.377698  0.260396  0.516424  0.883485\n",
       "409   0.647809  0.532714  0.427910  0.876192\n",
       "325   0.496219  0.273556  0.587736  0.638915\n",
       "...        ...       ...       ...       ...\n",
       "1095  0.192934  0.742470  0.252361  0.280186\n",
       "1130  0.217835  0.036390  0.900597  0.690302\n",
       "1294  0.151252  0.638870  0.273509  0.645971\n",
       "860   0.336225  0.461479  0.276279  0.791889\n",
       "1126  0.337437  0.511421  0.311013  0.880548\n",
       "\n",
       "[914 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CleanData():\n",
    "    \n",
    "    def __init__(self, file_url):\n",
    "        self.df = pd.read_csv(file_url)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"This dataframe looks like this: \\n\\n{}\".format(self.df.head())\n",
    "    \n",
    "    def getColumns(self):\n",
    "        return self.df.columns\n",
    "    \n",
    "    def setColumns(self, column_names):\n",
    "        self.df.columns = column_names\n",
    "        \n",
    "    def checkData(self):\n",
    "        \"\"\"\n",
    "        Check if the data contains any null values\n",
    "        \"\"\"\n",
    "        counter=0\n",
    "        for col_name in self.getColumns:\n",
    "            if  self.df[col_name].isnull().values.any():\n",
    "                # print(f\"the column {col_name} contains a null value\")\n",
    "                counter+=1\n",
    "        return counter\n",
    "    \n",
    "    def cleanData(self, column_names):\n",
    "        if all(element.isdigit() for element in self.getColumns()):  ##J'ai cahnge ca !\n",
    "            self.setColumns(column_names)\n",
    "        for col_name in self.getColumns():\n",
    "                if self.df[col_name].isnull().values.any():\n",
    "                    self.df[col_name] = self.df[col_name].fillna(method= 'bfill')\n",
    "        df_to_treat = (self.df.drop(\"id\", axis=1)) if (\"id\" in list(self.getColumns())) else self.df\n",
    "        df_to_treat= (self.df.drop(\"classification\", axis=1)) if (\"classification\" in list(self.getColumns())) else self.df\n",
    "        return df_to_treat\n",
    "\n",
    "    def normalizeData(self, dataframe,  method=\"minmax\"): # We don't want to change directlyy the attribute df because we need it after\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        for col_name in dataframe.columns:\n",
    "                if is_numeric_dtype(self.df[col_name]):\n",
    "                    dataframe[col_name] =  min_max_scaler.fit_transform(dataframe[col_name].values.astype(float).reshape(-1, 1))\n",
    "        return dataframe\n",
    "    \n",
    "    def arrangedData(self, test_size, random_state, *column_names):\n",
    "        self.new_df = self.normalizeData(self.cleanData(column_names[0]))\n",
    "        X,y = self.new_df, self.df[\"classification\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "        \n",
    "data1 = CleanData(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\")\n",
    "print(data1)\n",
    "column_names = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"classification\"]\n",
    "X_train, X_test, y_train, y_test = data1.arrangedData(1/3, 42, column_names)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\")\n",
    "#df = pd.read_csv(\"C:/Users/achraf/Desktop/IMT Atlantique/3A/Intro to ML/Projet-ML/kidney_disease.csv\")\n",
    "# add column names\n",
    "# df.columns=[\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "df.columns\n",
    "#df.describe(include = 'all').to_csv(sys.stdout, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise an example of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data contains any null values\n",
    "counter=0\n",
    "for col_name in df.columns:\n",
    "    if  df[col_name].isnull().values.any():\n",
    "        # print(f\"the column {col_name} contains a null value\")\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe):\n",
    "    if any(ele.isdigit() for ele in dataframe.columns):\n",
    "        print(\"entered\")\n",
    "        dataframe.columns=[\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"classification\"]\n",
    "    for col_name in dataframe.columns:\n",
    "            if  dataframe[col_name].isnull().values.any():\n",
    "               dataframe[col_name] = dataframe[col_name].fillna(method= 'bfill')\n",
    "                \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=clean_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_treat= df.drop([\"id\", \"classification\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataframe, method=\"minmax\"):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    for col_name in dataframe.columns:\n",
    "            if  is_numeric_dtype(dataframe[col_name]):\n",
    "               dataframe[col_name] =  min_max_scaler.fit_transform(dataframe[col_name].values.astype(float).reshape(-1, 1))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "new_df = normalize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min_max= (df-df.min())/(df.max()-df.min())\n",
    "# df_mean_std = (df-df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_data(dataframe, method=\"minmax\"):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()\n",
    "# df_mean_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data from the label\n",
    "X,y = new_df, df[\"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # seperate train data and test data\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvp= ShuffleSplit(1000, train_size=2/3)\n",
    "n_depths = 10\n",
    "depths = linspace(1, 10, n_depths)\n",
    "\n",
    "tab_RMSE_tree = zeros(n_depths)\n",
    "for i in range(n_depths):\n",
    "    reg_tree = DecisionTreeClassifier(max_depth=depths[i])\n",
    "    tab_RMSE_tree[i]  = median(sqrt(-cross_val_score(reg_tree, X_train, y_train, scoring='neg_log_loss', cv=cvp)))\n",
    "    \n",
    "# Plot\n",
    "plot(depths, tab_RMSE_tree)\n",
    "xlabel('Max depth of the tree', size=20)\n",
    "ylabel('RMSE', size=20)\n",
    "\n",
    "\n",
    "# reg_tree = DecisionTreeRegressor(max_depth=4)\n",
    "# reg_tree.fit(X_train, y_train)\n",
    "# y_tree = reg_tree.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_tree = DecisionTreeRegressor(max_depth=3)\n",
    "classif_tree.fit(X_train, y_train)\n",
    "y_bin_tree_predic = classif_tree.predict(X_test)\n",
    "y_bin_tree_predic= (y_bin_tree_predic>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2) : \n",
    "#     plt.figure()\n",
    "#     y_pred[i,:] = cls[i].predict(x)\n",
    "#     ConfusionMatrixDisplay(confusion_matrix= confusion_matrix(y,y_pred[i]),\n",
    "#                                 display_labels=cls[i].classes_).plot(figsize(8,5))\n",
    "# for i in range(2) : \n",
    "#     plt.figure()\n",
    "#     y_pred[i,:] = cls[i].predict(x)\n",
    "#     ConfusionMatrixDisplay(confusion_matrix= confusion_matrix(y,y_pred[i]),\n",
    "#                                 display_labels=cls[i].classes_).plot(figsize(8,5))\n",
    "# #Finally plot ROC Curves\n",
    "# for i in range(2) :\n",
    "#     plot_roc_curve(cls[i],x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_metric= sum(abs(y_bin_tree_predic- y_test))\n",
    "print(Result_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[5,4]\n",
    "A.sort()\n",
    "A"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffc7a7a309c64630ee0f15650faac6797805b97797853305f4920937eb630e3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
